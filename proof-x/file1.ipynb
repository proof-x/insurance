{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## WAL*MART\n",
      "\n",
      "Save money. Live better.\n",
      "\n",
      "8\n",
      "\n",
      "VE SELL FOR LESS ALways HANAGER DHFHNÃˆ SESSION (636 ) 536 4601 CHESTERFIELD Ho 63005 St# 2600 DFF 00001855 TET 77 TR#03359 SV FIGURES 065356920144 6,63 X TOoThBRush 003500055500 88 WOHEN SLIPPE 009725827939L 9 X SuBtoTaL 1 Tax 3 3780 K 8 1 TotaL 1 hcard TEND 18\n",
      "\n",
      "ACcount  #3546 ApPRovaL *007190\n",
      "\n",
      "VALIDATION\n",
      "\n",
      "TRANs ID\n",
      "\n",
      "TRANs ID\n",
      "\n",
      "PAYMENT SERVICE\n",
      "\n",
      "CHANGE DUE\n",
      "\n",
      "0,0o\n",
      "\n",
      "## # ITEHS SOLD 3\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "ai-Horf exclugive Eables CD avellable October 30th! 10/20707 13,48;43\n",
      "\n",
      "###CUSTOHER CoPYx*x\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "source = r\"images\\12.jpg\"  # PDF path or URL\n",
    "# converter = DocumentConverter()\n",
    " # output: \"### Docling Technical Report[...]\"\n",
    "\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "pipeline_options = PdfPipelineOptions(do_table_structure=True)\n",
    "pipeline_options.table_structure_options.do_cell_matching = False  # uses text cells predicted from table structure model\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "result = doc_converter.convert(source)\n",
    "print(result.document.export_to_markdown()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode\n",
    "\n",
    "pipeline_options = PdfPipelineOptions(do_table_structure=True)\n",
    "pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE  # use more accurate TableFormer model\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for DocumentConverter.convert\n1.lax-or-strict[lax=union[json-or-python[json=function-after[path_validator(), str],python=is-instance[Path]],function-after[path_validator(), str]],strict=json-or-python[json=function-after[path_validator(), str],python=is-instance[Path]]]\n  Input should be an instance of Path [type=is_instance_of, input_value=<PIL.Image.Image image mo...8x1024 at 0x17FECCE1310>, input_type=Image]\n    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of\n1.str\n  Input should be a valid string [type=string_type, input_value=<PIL.Image.Image image mo...8x1024 at 0x17FECCE1310>, input_type=Image]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type\n1.DocumentStream\n  Input should be a valid dictionary or instance of DocumentStream [type=model_type, input_value=<PIL.Image.Image image mo...8x1024 at 0x17FECCE1310>, input_type=Image]\n    For further information visit https://errors.pydantic.dev/2.10/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m source\u001b[38;5;241m=\u001b[39ma\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;66;03m# Path to PDF or image\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdoc_converter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Post-process and display results\u001b[39;00m\n\u001b[0;32m     31\u001b[0m output_text \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdocument\u001b[38;5;241m.\u001b[39mexport_to_markdown()\n",
      "File \u001b[1;32mc:\\Users\\rafey\\OneDrive - Veracitiz Solutions Pvt Ltd\\Desktop\\proof-x\\myvenv2\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:38\u001b[0m, in \u001b[0;36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrapped)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rafey\\OneDrive - Veracitiz Solutions Pvt Ltd\\Desktop\\proof-x\\myvenv2\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:111\u001b[0m, in \u001b[0;36mValidateCallWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 111\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__:\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__(res)\n",
      "\u001b[1;31mValidationError\u001b[0m: 3 validation errors for DocumentConverter.convert\n1.lax-or-strict[lax=union[json-or-python[json=function-after[path_validator(), str],python=is-instance[Path]],function-after[path_validator(), str]],strict=json-or-python[json=function-after[path_validator(), str],python=is-instance[Path]]]\n  Input should be an instance of Path [type=is_instance_of, input_value=<PIL.Image.Image image mo...8x1024 at 0x17FECCE1310>, input_type=Image]\n    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of\n1.str\n  Input should be a valid string [type=string_type, input_value=<PIL.Image.Image image mo...8x1024 at 0x17FECCE1310>, input_type=Image]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type\n1.DocumentStream\n  Input should be a valid dictionary or instance of DocumentStream [type=model_type, input_value=<PIL.Image.Image image mo...8x1024 at 0x17FECCE1310>, input_type=Image]\n    For further information visit https://errors.pydantic.dev/2.10/v/model_type"
     ]
    }
   ],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert('L')  # Convert to grayscale\n",
    "    image = image.filter(ImageFilter.SHARPEN)  # Enhance sharpness\n",
    "    return image\n",
    "# Define improved pipeline options\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_table_structure=True,\n",
    "    do_layout_analysis=True  # Enable layout analysis\n",
    ")\n",
    "pipeline_options.table_structure_options.do_cell_matching = True\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "a=preprocess_image(r\"images\\12.jpg\")\n",
    "  # Path to PDF or image\n",
    "result = doc_converter.convert(source)\n",
    "\n",
    "# Post-process and display results\n",
    "output_text = result.document.export_to_markdown()\n",
    "print(\"Extracted Text:\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doctr.io import DocumentFile\n",
    "# PDF\n",
    "# pdf_doc = DocumentFile.from_pdf(\"path/to/your/doc.pdf\")\n",
    "# # Image\n",
    "single_img_doc = DocumentFile.from_images(r\"images\\13.jpg\")\n",
    "# Webpage (requires `weasyprint` to be installed)\n",
    "# webpage_doc = DocumentFile.from_url(\"https://www.yoursite.com\")\n",
    "# # Multiple page images\n",
    "# multi_img_doc = DocumentFile.from_images([\"path/to/page1.jpg\", \"path/to/page2.jpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://doctr-static.mindee.com/models?id=v0.8.1/fast_base-688a8b34.pt&src=0 to C:\\Users\\rafey\\.cache\\doctr\\models\\fast_base-688a8b34.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65815552it [00:14, 4627103.37it/s]                              \n",
      "c:\\Users\\rafey\\OneDrive - Veracitiz Solutions Pvt Ltd\\Desktop\\proof-x\\.venv\\Lib\\site-packages\\doctr\\models\\utils\\pytorch.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(archive_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://doctr-static.mindee.com/models?id=v0.3.1/crnn_vgg16_bn-9762b0b0.pt&src=0 to C:\\Users\\rafey\\.cache\\doctr\\models\\crnn_vgg16_bn-9762b0b0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63287296it [00:06, 10470455.84it/s]                              \n"
     ]
    }
   ],
   "source": [
    "from doctr.models import ocr_predictor\n",
    "\n",
    "model = ocr_predictor(pretrained=True)\n",
    "# PDF\n",
    "doc = single_img_doc\n",
    "# Analyze\n",
    "result = model(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(\n",
       "  (pages): [Page(\n",
       "    dimensions=(745, 737)\n",
       "    (blocks): [Block(\n",
       "      (lines): [\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='ID', confidence=0.76),\n",
       "            Word(value='#:', confidence=0.67),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='1SWOYBKCH', confidence=0.55)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='Walmart', confidence=0.99),\n",
       "            Word(value='t*', confidence=0.56),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='Save', confidence=1.0),\n",
       "            Word(value='money.', confidence=0.83),\n",
       "            Word(value='Live', confidence=1.0),\n",
       "            Word(value='better.', confidence=0.99),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='(', confidence=0.97),\n",
       "            Word(value='843', confidence=1.0),\n",
       "            Word(value=')', confidence=1.0),\n",
       "            Word(value='292', confidence=1.0),\n",
       "            Word(value='-', confidence=0.93),\n",
       "            Word(value='0362', confidence=1.0),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='MANAGER', confidence=1.0),\n",
       "            Word(value='MICHAEL', confidence=0.94),\n",
       "            Word(value='EIGHARD', confidence=0.87),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='2014', confidence=1.0),\n",
       "            Word(value='S', confidence=0.89),\n",
       "            Word(value='IRBY', confidence=0.64),\n",
       "            Word(value='ST', confidence=1.0),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='FLORENCE', confidence=0.94),\n",
       "            Word(value='SC', confidence=0.76),\n",
       "            Word(value='29505', confidence=0.79),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='SI#', confidence=0.56),\n",
       "            Word(value='02703', confidence=0.97),\n",
       "            Word(value='OP#', confidence=0.99),\n",
       "            Word(value='009049', confidence=0.85),\n",
       "            Word(value='TEL', confidence=0.75),\n",
       "            Word(value='49', confidence=0.65),\n",
       "            Word(value='TRE', confidence=0.35),\n",
       "            Word(value='07142', confidence=0.81),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='GIFT', confidence=0.79),\n",
       "            Word(value='CARD', confidence=0.47),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='08/458604383', confidence=0.96)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='50,00', confidence=0.89),\n",
       "            Word(value='0', confidence=0.99),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='SUBTOTAL', confidence=0.98)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='50.00', confidence=0.99)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='OTAL', confidence=0.55)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='50.00', confidence=0.99)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='CASHI', confidence=0.68),\n",
       "            Word(value='N)', confidence=0.55),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='60.00', confidence=1.0)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='CHANGE', confidence=0.98),\n",
       "            Word(value='DUE', confidence=0.94),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='10.00', confidence=0.95)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='SHOP.CARD', confidence=0.89),\n",
       "            Word(value='ACTIVATION', confidence=0.98),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='50.00', confidence=0.84)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='ACCOUNT', confidence=1.0),\n",
       "            Word(value='613968546249/297', confidence=0.5),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='APPR,', confidence=0.42),\n",
       "            Word(value='CODE', confidence=1.0),\n",
       "            Word(value='-', confidence=0.97),\n",
       "            Word(value='792986', confidence=0.99),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='REF', confidence=1.0),\n",
       "            Word(value='0083742', confidence=0.29),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='Beg,', confidence=0.56),\n",
       "            Word(value='Bal', confidence=1.0),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='ran', confidence=0.91),\n",
       "            Word(value='Ami', confidence=0.43),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='End', confidence=0.95),\n",
       "            Word(value='Bal', confidence=1.0),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='0.00', confidence=0.95)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='5000', confidence=0.56)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='50.00', confidence=0.99)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='08/11/17', confidence=0.99)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='19:19:31', confidence=0.98)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='TCH', confidence=0.56),\n",
       "            Word(value='9/36', confidence=0.93),\n",
       "            Word(value='5895', confidence=0.95),\n",
       "            Word(value='923/', confidence=0.9),\n",
       "            Word(value='2333', confidence=1.0),\n",
       "            Word(value='1932', confidence=1.0),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='Low', confidence=0.99),\n",
       "            Word(value='Prices', confidence=0.89),\n",
       "            Word(value='You', confidence=0.96),\n",
       "            Word(value='Can', confidence=0.98),\n",
       "            Word(value='Trust.', confidence=0.52),\n",
       "            Word(value='Every', confidence=0.85),\n",
       "            Word(value='Day.', confidence=1.0),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='08/11/17', confidence=0.52)]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='19', confidence=0.35),\n",
       "            Word(value='22:40', confidence=0.9),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [\n",
       "            Word(value='Store', confidence=0.99),\n",
       "            Word(value='receipis', confidence=0.87),\n",
       "            Word(value='on', confidence=0.97),\n",
       "            Word(value='your', confidence=0.81),\n",
       "            Word(value='one.', confidence=0.76),\n",
       "            Word(value='Walmart', confidence=0.99),\n",
       "            Word(value='P', confidence=1.0),\n",
       "          ]\n",
       "        ),\n",
       "        Line(\n",
       "          (words): [Word(value='ay.', confidence=0.93)]\n",
       "        ),\n",
       "      ]\n",
       "      (artefacts): []\n",
       "    )]\n",
       "  )]\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-doctr[torch]\n",
      "  Using cached python_doctr-0.10.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting numpy<3.0.0,>=1.16.0 (from python-doctr[torch])\n",
      "  Using cached numpy-2.2.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scipy<2.0.0,>=1.4.0 (from python-doctr[torch])\n",
      "  Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py<4.0.0,>=3.1.0 (from python-doctr[torch])\n",
      "  Using cached h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting opencv-python<5.0.0,>=4.5.0 (from python-doctr[torch])\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting pypdfium2<5.0.0,>=4.11.0 (from python-doctr[torch])\n",
      "  Using cached pypdfium2-4.30.0-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Collecting pyclipper<2.0.0,>=1.2.0 (from python-doctr[torch])\n",
      "  Using cached pyclipper-1.3.0.post6-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting shapely<3.0.0,>=1.6.0 (from python-doctr[torch])\n",
      "  Using cached shapely-2.0.6-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "Collecting langdetect<2.0.0,>=1.0.9 (from python-doctr[torch])\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Collecting rapidfuzz<4.0.0,>=3.0.0 (from python-doctr[torch])\n",
      "  Using cached rapidfuzz-3.10.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.20.0 (from python-doctr[torch])\n",
      "  Using cached huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow>=9.2.0 (from python-doctr[torch])\n",
      "  Using cached pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting defusedxml>=0.7.0 (from python-doctr[torch])\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting anyascii>=0.3.2 (from python-doctr[torch])\n",
      "  Using cached anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tqdm>=4.30.0 (from python-doctr[torch])\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch<3.0.0,>=2.0.0 (from python-doctr[torch])\n",
      "  Using cached torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.15.0 (from python-doctr[torch])\n",
      "  Using cached torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Collecting onnx<3.0.0,>=1.12.0 (from python-doctr[torch])\n",
      "  Using cached onnx-1.17.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch])\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch])\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\rafey\\onedrive - veracitiz solutions pvt ltd\\desktop\\proof-x\\.venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rafey\\onedrive - veracitiz solutions pvt ltd\\desktop\\proof-x\\.venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\rafey\\onedrive - veracitiz solutions pvt ltd\\desktop\\proof-x\\.venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (2.32.3)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch])\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: six in c:\\users\\rafey\\onedrive - veracitiz solutions pvt ltd\\desktop\\proof-x\\.venv\\lib\\site-packages (from langdetect<2.0.0,>=1.0.9->python-doctr[torch]) (1.17.0)\n",
      "Collecting protobuf>=3.20.2 (from onnx<3.0.0,>=1.12.0->python-doctr[torch])\n",
      "  Using cached protobuf-5.29.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting networkx (from torch<3.0.0,>=2.0.0->python-doctr[torch])\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch<3.0.0,>=2.0.0->python-doctr[torch])\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting setuptools (from torch<3.0.0,>=2.0.0->python-doctr[torch])\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch<3.0.0,>=2.0.0->python-doctr[torch])\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3.0.0,>=2.0.0->python-doctr[torch])\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rafey\\onedrive - veracitiz solutions pvt ltd\\desktop\\proof-x\\.venv\\lib\\site-packages (from tqdm>=4.30.0->python-doctr[torch]) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch<3.0.0,>=2.0.0->python-doctr[torch])\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rafey\\onedrive - veracitiz solutions pvt ltd\\desktop\\proof-x\\.venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rafey\\onedrive - veracitiz solutions pvt ltd\\desktop\\proof-x\\.venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rafey\\onedrive - veracitiz solutions pvt ltd\\desktop\\proof-x\\.venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rafey\\onedrive - veracitiz solutions pvt ltd\\desktop\\proof-x\\.venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (2024.8.30)\n",
      "Using cached anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "Using cached huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Using cached numpy-2.2.0-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached onnx-1.17.0-cp312-cp312-win_amd64.whl (14.5 MB)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached pyclipper-1.3.0.post6-cp312-cp312-win_amd64.whl (110 kB)\n",
      "Using cached pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
      "Using cached rapidfuzz-3.10.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Using cached shapely-2.0.6-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "Using cached torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached python_doctr-0.10.0-py3-none-any.whl (304 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached protobuf-5.29.1-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: pyclipper, mpmath, typing-extensions, tqdm, sympy, setuptools, rapidfuzz, pypdfium2, protobuf, Pillow, numpy, networkx, MarkupSafe, langdetect, fsspec, filelock, defusedxml, anyascii, shapely, scipy, opencv-python, onnx, jinja2, huggingface-hub, h5py, torch, python-doctr, torchvision\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.0.0 anyascii-0.3.2 defusedxml-0.7.1 filelock-3.16.1 fsspec-2024.10.0 h5py-3.12.1 huggingface-hub-0.26.5 jinja2-3.1.4 langdetect-1.0.9 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.0 onnx-1.17.0 opencv-python-4.10.0.84 protobuf-5.29.1 pyclipper-1.3.0.post6 pypdfium2-4.30.0 python-doctr-0.10.0 rapidfuzz-3.10.1 scipy-1.14.1 setuptools-75.6.0 shapely-2.0.6 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 tqdm-4.67.1 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "# for TensorFlow\n",
    "!pip install \"python-doctr[torch]\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting doctr\n",
      "  Using cached doctr-1.9.0-py3-none-any.whl.metadata (594 bytes)\n",
      "Collecting pyyaml (from doctr)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from doctr)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting cryptography (from doctr)\n",
      "  Using cached cryptography-44.0.0-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=1.12 (from cryptography->doctr)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->doctr)\n",
      "  Using cached charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->doctr)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->doctr)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->doctr)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography->doctr)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Using cached doctr-1.9.0-py3-none-any.whl (27 kB)\n",
      "Using cached cryptography-44.0.0-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: urllib3, pyyaml, pycparser, idna, charset-normalizer, certifi, requests, cffi, cryptography, doctr\n",
      "Successfully installed certifi-2024.8.30 cffi-1.17.1 charset-normalizer-3.4.0 cryptography-44.0.0 doctr-1.9.0 idna-3.10 pycparser-2.22 pyyaml-6.0.2 requests-2.32.3 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install doctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
